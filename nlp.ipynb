{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"datasets/spacy_ds.csv\", delimiter=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, row in data.iterrows():\n",
    "    text = row['text']\n",
    "    origin = row['origin']\n",
    "    destination = row['destination']\n",
    "    detours = row['detours'] if pd.notna(row['detours']) else \"\"\n",
    "    \n",
    "    if origin != \"NOT_TRIP\":\n",
    "        start_origin = text.lower().find(origin)\n",
    "        end_origin = start_origin + len(origin)\n",
    "        start_destination = text.lower().find(destination)\n",
    "        end_destination = start_destination + len(destination)\n",
    "        detour_positions = []\n",
    "        \n",
    "        if detours:\n",
    "            for detour in detours.split(\",\"):\n",
    "                detour = detour.strip()\n",
    "                start_detour = text.lower().find(detour)\n",
    "                end_detour = start_detour + len(detour)\n",
    "                \n",
    "                if start_detour >= 0 and (\n",
    "                    end_detour <= start_origin or start_detour >= end_origin\n",
    "                ) and (\n",
    "                    end_detour <= start_destination or start_detour >= end_destination\n",
    "                ):\n",
    "                    overlap = any(\n",
    "                        (start < end_detour and end > start_detour)\n",
    "                        for start, end, _ in detour_positions\n",
    "                    )\n",
    "                    if not overlap:\n",
    "                        detour_positions.append((start_detour, end_detour, \"DETOUR\"))\n",
    "        \n",
    "        if start_origin >= 0 and start_destination >= 0 and end_origin <= start_destination:\n",
    "            entities = [\n",
    "                (start_origin, end_origin, \"ORIGIN\"),\n",
    "                (start_destination, end_destination, \"DESTINATION\")\n",
    "            ] + detour_positions\n",
    "\n",
    "            train_data.append((text, {\"entities\": entities}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.training.example import Example\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.blank(\"fr\")\n",
    "\n",
    "if \"ner\" not in nlp.pipe_names:\n",
    "    ner = nlp.add_pipe(\"ner\", last=True)\n",
    "else:\n",
    "    ner = nlp.get_pipe(\"ner\")\n",
    "\n",
    "ner.add_label(\"ORIGIN\")\n",
    "ner.add_label(\"DESTINATION\")\n",
    "ner.add_label(\"DETOUR\")\n",
    "\n",
    "optimizer = nlp.begin_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for itn in range(10):\n",
    "    random.shuffle(train_data)\n",
    "    losses = {}\n",
    "    for text, annotations in train_data:\n",
    "        example = Example.from_dict(nlp.make_doc(text), annotations)\n",
    "        nlp.update([example], losses=losses, drop=0.5, sgd=optimizer)\n",
    "    print(f\"Itération {itn} - Losses: {losses}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.to_disk(\"models/spacy_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('./model_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langdetect import detect, LangDetectException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_french(text):\n",
    "    try:\n",
    "        return detect(text) == \"fr\"\n",
    "    except LangDetectException:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unidecode import unidecode\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_trip_request(text):\n",
    "    if not is_french(text):\n",
    "        return \"NOT_FRENCH\"\n",
    "    \n",
    "    text = unidecode(text).lower()\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "\n",
    "    doc = nlp(text)\n",
    "    origin, destination = None, None\n",
    "    detours = []\n",
    "\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ == \"ORIGIN\":\n",
    "            origin = ent.text\n",
    "        elif ent.label_ == \"DESTINATION\":\n",
    "            destination = ent.text\n",
    "        elif ent.label_ == \"DETOUR\":\n",
    "            detours.append(ent.text)\n",
    "    \n",
    "    if origin and destination:\n",
    "        return (text, origin, destination, detours)\n",
    "    else:\n",
    "        return \"NOT_TRIP\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_infos(origin, destination, detours):\n",
    "    print(f'Depart: {origin}')\n",
    "    print(f'Arrivée: {destination}')\n",
    "    detours_sentence = \"\"\n",
    "    for i in range(len(detours)):\n",
    "        if(i == len(detours) - 1):\n",
    "            detours_sentence += detours[i]\n",
    "        else:\n",
    "            detours_sentence += detours[i] + \", \"\n",
    "    print(f'Détours: {detours_sentence if len(detours) > 0 else \"Aucun\"}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_phrases = [\n",
    "    \"Je veux aller de paris à vendenheim\",\n",
    "    \"J'aimerai aller de lille à nice\",\n",
    "    \"Voyage de rouen jusqu'à nice\",\n",
    "    \"Quel est le trajet de toulouse à bordeaux ?\",\n",
    "    \"Je veux aller de paris à lyon en passant par nice\",\n",
    "    \"En passant par toulouse, je veux aller de paris à lyon\",\n",
    "    \"What time is it in Paris ?\",\n",
    "    \"Quel est le trajet de strasbourg à bordeaux ?\",\n",
    "    \"Quel est le trajet de bordeaux à strasbourg en passant par lyon ?\",\n",
    "    \"Comment me rendre à strasbourg depuis nice ?\",\n",
    "    \"En passant par Lyon, j'aimerai aller à Nice depuis Strasbourg\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for phrase in test_phrases:\n",
    "    print(f\"sentence: {phrase}\")\n",
    "    print(test_trip_request(phrase.lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase = \"j'aimerais me rendre à lyon depuis strasbourg\"\n",
    "test_trip_request(phrase)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
